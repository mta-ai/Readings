# Mount Allison Artificial Intelligence Society Readings
## Winter 2019, Week 6.

### Theme: Introduction to Neural Networks part 3.

#### Note: This week we will look at a revolutionary method of allowing neural networks to learn, namely backpropagation. As the name suggests, this method allows errors in the predictions of a neural network to propagate backwards, adjusting the weights of prior neurons based on how much they contributed to the erroneous output. This breakthrough is partially responsible for the recent AI revolution; it allows us to train neural networks much faster and at a lower expense. The included paper is the original letter that introduced backpropagation to the world.

## Core:
[What is backpropagation really doing?(video)](https://www.youtube.com/watch?v=Ilg3gGewQ5U&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=3)

[Backpropagation calculus (video)](https://www.youtube.com/watch?v=tIeHLnjs5U8&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=4)

[Learning representations by back-propagating errors (paper)](https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf)
